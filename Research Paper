Research Paper

Title: Label Correction Strategy on Hierarchical Multi-Label Classification
Author: Thanawut Ananpiriyakul, Piyapan Poomsirivilai, Peerapon Vateekul
Institution: Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand
Conference: 10th International Conference on Machine Learning and Data Mining (MLDM 2014)

Abstract
One of the most popular approaches to solve hierarchical multi-label classification problem is to induce Support Vector Machine (SVM) for each class in the hierarchy independently and employ them in a top-down fashion. This approach always suffers from error propagation and yields such a poor performance of classifiers at the lower levels since no label correlation is considered during the construction. In this paper, we present a novel method called “label correction”, which takes label correlation into consideration and corrects the results of unusual prediction patterns. In the experiment, our method does not only improve prediction accuracy on data in hierarchical domains, but it also contributes such a significant impact on data in multi-label domains.

Keyword: Hierarchical Multi-Label Classification, Multi-Label Classification, Label Correlation, Support Vector Machine

Introduction
Over the last decade or so, the need for systems capable of automated classification has become more urgent and complex. The most traditional classification assumes that each example can be assigned to only one out of two or more classes. However, a more complex scenario called “Hierarchical Multi-Label Classification (HMC)” has recently received numerous attentions from various applications. It is different from the conservative one in two aspects: (i) multi-label classification: each example can belong to more than one class simultaneously, and (ii) hierarchical classification: classes are organized in the form of hierarchy.
Support Vector Machine (SVM) [1,2] is the state-of-the-art in classification techniques. It is originally used as a binary classifier by constructing a hyperplane to separate between positive and negative classes. In the multi-label domain, the problem is needed to be transformed in order to employ SVM. The most common approach is called Binary Relevance (BR) [3,4] which constructs a one-vs-all classifier for each class separately without a consideration in a class correlation; thus, it often results in low prediction accuracy. Label Powerset (LP) [5] is an alternative approach which takes a label correlation into account. It induces a set of binary classifiers equal to the number of all possible class combinations; thus, it has prohibitive computational cost and low scalability. Since the number of classes can be very large, it is impossible to apply LP, so BR is only an option. It will be referred to as “SVM-BR”, as a baseline method.
In the hierarchical domain, a set of classifiers in the BR approach is modified and used in a top-down fashion from more general to more specific classifiers in order to satisfy a hierarchical constraint – if an example belongs to class ci, it must belong to ci’s ancestor classes. With this strategy, classifiers at the lower levels always suffer very much from errors generated by those at the upper levels, which is known as a propagated error. The more the levels in the hierarchy, the less the prediction performance.
Since HMC is a composite of multi-label and hierarchical classifications, it inherits the issues from both domains including (i) label correlation and (ii) error propagation. In this paper, we introduce a novel method called “Label Correction (LC)” to improve prediction accuracy in the HMC domain by focusing on both issues. For the label correlation issue, there is a hypothesis that the same set of class labels should be used to annotate examples throughout the dataset; therefore, a set of class labels in the testing data should be same or close to that in the training data. According to this hypothesis, for a given testing example, if a prediction label set does not match to any label sets occurred in the training data, it should be corrected to the closest training label set. For the error propagation issue, the proposed label correction is enhanced by taking a hierarchical relationship into account. Since subclasses have a strong correlation to their superclasses in the hierarchy, our strategy can correct propagated errors by using such a relationship and regain performance specifically of classifiers at the lower levels of the hierarchy. 
To provide a strong evidence of the improvement, the experiments were intensively conducted on several benchmark datasets: 22 multi-label datasets and 10 HMC datasets. The results comparing to the baseline SVM show that there is a significant improvement on 18 multi-label datasets and 8 HMC datasets. Moreover, in all HMC datasets, the performance of classifiers at the lower levels is tremendously improved. In the D15_scop_GO dataset, an average performance of the deepest-level classifiers is increased by 250% over the baseline SVM.
The rest of the paper is organized as follows. Section 2 introduces problem transformation and SVM. Section 3 declares relevant performance criteria. Section 4 describes the proposed method in detail. Section 5 shows the results of extensive experiment and discussion. Section 6 is the conclusion of this paper.
